"""
ç»˜åˆ¶è®­ç»ƒlossæ›²çº¿å¹¶æ£€æµ‹è¿‡æ‹Ÿåˆ
æ”¯æŒä» checkpoint æ–‡ä»¶æˆ– JSON æ–‡ä»¶è¯»å–è®­ç»ƒå†å²ï¼Œå¹¶æ”¯æŒç»˜åˆ¶ Dice å’Œ IoU æ›²çº¿
"""
import json
import os
import glob
import torch
import matplotlib.pyplot as plt
import numpy as np
import argparse


def load_history_from_checkpoints(checkpoint_dir='checkpoints'):
    """
    ä» checkpoint æ–‡ä»¶ä¸­æå–è®­ç»ƒå†å²
    æ¯ä¸ª checkpoint æ–‡ä»¶åŒ…å«: epoch, train_loss, val_loss, ä»¥åŠå¯é€‰çš„ val_dice, val_iou
    """
    checkpoint_files = glob.glob(os.path.join(checkpoint_dir, 'checkpoint_epoch_*.pth'))
    best_model_path = os.path.join(checkpoint_dir, 'best_model.pth')
    
    if os.path.exists(best_model_path):
        checkpoint_files.append(best_model_path)
    
    if not checkpoint_files:
        raise FileNotFoundError(f"åœ¨ {checkpoint_dir} ä¸­æœªæ‰¾åˆ° checkpoint æ–‡ä»¶")
    
    history_data = []
    
    for ckpt_path in checkpoint_files:
        try:
            ckpt = torch.load(ckpt_path, map_location='cpu')
            
            if 'epoch' in ckpt and 'train_loss' in ckpt and 'val_loss' in ckpt:
                # å°è¯•æå–åŸºç¡€ä¿¡æ¯ä»¥åŠæ–°å¢çš„æŒ‡æ ‡ä¿¡æ¯ (ä½¿ç”¨ get é˜²æ­¢è€æ¨¡å‹æŠ¥é”™)
                history_data.append({
                    'epoch': ckpt['epoch'],
                    'train_loss': ckpt['train_loss'],
                    'val_loss': ckpt['val_loss'],
                    'val_dice': ckpt.get('val_dice', None), # è·å– Dice
                    'val_iou': ckpt.get('val_iou', None)    # è·å– IoU
                })
            else:
                print(f"è­¦å‘Š: {ckpt_path} ä¸­ç¼ºå°‘è®­ç»ƒå†å²ï¼Œè·³è¿‡")
        except Exception as e:
            print(f"è­¦å‘Š: æ— æ³•åŠ è½½ {ckpt_path}: {e}")
            continue
    
    if not history_data:
        raise ValueError("æ²¡æœ‰æ‰¾åˆ°åŒ…å«è®­ç»ƒå†å²çš„ checkpoint æ–‡ä»¶")
    
    # æŒ‰ epoch æ’åº
    history_data.sort(key=lambda x: x['epoch'])
    
    # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼ï¼Œè‡ªåŠ¨è¿‡æ»¤æ‰æ²¡æœ‰æŒ‡æ ‡çš„å†å²è®°å½•
    history = {
        'epoch': [d['epoch'] for d in history_data],
        'train_loss': [d['train_loss'] for d in history_data],
        'val_loss': [d['val_loss'] for d in history_data],
        'val_dice': [d['val_dice'] for d in history_data if d['val_dice'] is not None],
        'val_iou': [d['val_iou'] for d in history_data if d['val_iou'] is not None]
    }
    
    print(f"ä» {len(history_data)} ä¸ª checkpoint æ–‡ä»¶ä¸­æå–è®­ç»ƒå†å²")
    return history


def load_history(history_path):
    """åŠ è½½è®­ç»ƒå†å²ï¼ˆä» JSON æ–‡ä»¶ï¼‰"""
    if not os.path.exists(history_path):
        raise FileNotFoundError(f"Losså†å²æ–‡ä»¶ä¸å­˜åœ¨: {history_path}")
    with open(history_path, 'r') as f:
        history = json.load(f)
    return history


def detect_overfitting(history, window=5):
    """æ£€æµ‹è¿‡æ‹Ÿåˆé€»è¾‘ä¿æŒä¸å˜"""
    train_loss = np.array(history['train_loss'])
    val_loss = np.array(history['val_loss'])
    epochs = np.array(history['epoch'])
    
    if len(train_loss) < window:
        return None, "æ•°æ®ç‚¹ä¸è¶³ï¼Œæ— æ³•åˆ¤æ–­"
    
    train_trend = np.mean(np.diff(train_loss[-window:]))
    val_trend = np.mean(np.diff(val_loss[-window:]))
    gap = val_loss - train_loss
    gap_trend = np.mean(np.diff(gap[-window:]))
    
    is_overfitting = False
    warning_msg = ""
    
    if val_trend > 0 and train_trend < 0:
        is_overfitting = True
        warning_msg = f"âš ï¸ æ£€æµ‹åˆ°è¿‡æ‹Ÿåˆï¼è®­ç»ƒlossä¸‹é™({train_trend:.4f})ï¼Œä½†éªŒè¯lossä¸Šå‡({val_trend:.4f})"
    elif gap_trend > 0.01:
        is_overfitting = True
        warning_msg = f"âš ï¸ æ£€æµ‹åˆ°è¿‡æ‹Ÿåˆï¼è®­ç»ƒå’ŒéªŒè¯losså·®è·åœ¨å¢å¤§({gap_trend:.4f})"
    elif val_trend > 0.001:
        warning_msg = f"âš ï¸ è­¦å‘Šï¼šéªŒè¯lossæœ‰ä¸Šå‡è¶‹åŠ¿({val_trend:.4f})ï¼Œå¯èƒ½å‡ºç°è¿‡æ‹Ÿåˆ"
    else:
        warning_msg = "âœ… è®­ç»ƒæ­£å¸¸ï¼Œæœªæ£€æµ‹åˆ°æ˜æ˜¾è¿‡æ‹Ÿåˆ"
    
    best_epoch_idx = np.argmin(val_loss)
    best_epoch = epochs[best_epoch_idx]
    best_val_loss = val_loss[best_epoch_idx]
    
    return {
        'is_overfitting': is_overfitting,
        'warning': warning_msg,
        'best_epoch': int(best_epoch),
        'best_val_loss': float(best_val_loss),
        'train_trend': float(train_trend),
        'val_trend': float(val_trend),
        'gap_trend': float(gap_trend),
        'final_gap': float(gap[-1])
    }, None


def plot_curves(history, save_path='checkpoints/training_curves.png', show_plot=True):
    """ç»˜åˆ¶è®­ç»ƒæ›²çº¿ (æ–°å¢ Dice å’Œ IoU æ”¯æŒ)"""
    epochs = history['epoch']
    train_loss = history['train_loss']
    val_loss = history['val_loss']
    val_dice = history.get('val_dice', [])
    val_iou = history.get('val_iou', [])
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è¯„ä¼°æŒ‡æ ‡æ•°æ®
    has_metrics = len(val_dice) > 0 or len(val_iou) > 0
    
    # å¦‚æœæœ‰æŒ‡æ ‡æ•°æ®ï¼Œç”» 3 ä¸ªå­å›¾ï¼Œå¦åˆ™ç”» 2 ä¸ª
    if has_metrics:
        plt.figure(figsize=(18, 5))
        total_subplots = 3
    else:
        plt.figure(figsize=(12, 5))
        total_subplots = 2
        print("\nğŸ’¡ æç¤ºï¼šæœªåœ¨ checkpoint ä¸­æ£€æµ‹åˆ° val_dice æˆ– val_iou æ•°æ®ï¼Œä»…ç»˜åˆ¶ Loss æ›²çº¿ã€‚")
    
    # å­å›¾1: Lossæ›²çº¿
    plt.subplot(1, total_subplots, 1)
    plt.plot(epochs, train_loss, 'b-', label='Train Loss', linewidth=2)
    plt.plot(epochs, val_loss, 'r-', label='Val Loss', linewidth=2)
    plt.xlabel('Epoch', fontsize=12)
    plt.ylabel('Loss', fontsize=12)
    plt.title('Training and Validation Loss', fontsize=14, fontweight='bold')
    plt.legend(fontsize=11)
    plt.grid(True, alpha=0.3)
    
    best_idx = np.argmin(val_loss)
    best_epoch = epochs[best_idx]
    best_val = val_loss[best_idx]
    plt.plot(best_epoch, best_val, 'go', markersize=10)
    plt.annotate(f'Epoch {best_epoch}\nLoss: {best_val:.4f}', 
                 xy=(best_epoch, best_val), xytext=(10, 10), textcoords='offset points',
                 bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.7),
                 arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))
    
    # å­å›¾2: Losså·®è·ï¼ˆè¿‡æ‹ŸåˆæŒ‡æ ‡ï¼‰
    plt.subplot(1, total_subplots, 2)
    gap = np.array(val_loss) - np.array(train_loss)
    plt.plot(epochs, gap, 'g-', label='Val Loss - Train Loss', linewidth=2)
    plt.axhline(y=0, color='k', linestyle='--', alpha=0.3)
    plt.xlabel('Epoch', fontsize=12)
    plt.ylabel('Loss Gap', fontsize=12)
    plt.title('Overfitting Indicator', fontsize=14, fontweight='bold')
    plt.legend(fontsize=11)
    plt.grid(True, alpha=0.3)
    
    if len(gap) > 5:
        recent_gap = gap[-5:]
        if np.mean(np.diff(recent_gap)) > 0:
            plt.fill_between(epochs[-5:], gap[-5:], alpha=0.3, color='red', label='Increasing Gap')
    
    # å­å›¾3: è¯„ä¼°æŒ‡æ ‡æ›²çº¿ (Dice & IoU)
    if has_metrics:
        plt.subplot(1, total_subplots, 3)
        if len(val_dice) > 0:
            # å–æœ€åçš„å¯¹åº”é•¿åº¦ epochs ç”»å›¾ï¼Œé˜²æ­¢åˆ—è¡¨é•¿åº¦ä¸ä¸€è‡´
            plt.plot(epochs[-len(val_dice):], val_dice, color='#2ca02c', linestyle='-', label='Val Dice', linewidth=2)
        if len(val_iou) > 0:
            plt.plot(epochs[-len(val_iou):], val_iou, color='#9467bd', linestyle='-', label='Val IoU', linewidth=2)
        plt.xlabel('Epoch', fontsize=12)
        plt.ylabel('Score', fontsize=12)
        plt.title('Validation Metrics (Dice & IoU)', fontsize=14, fontweight='bold')
        plt.legend(fontsize=11)
        plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    os.makedirs(os.path.dirname(save_path) if os.path.dirname(save_path) else '.', exist_ok=True)
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"è®­ç»ƒæ›²çº¿å·²ä¿å­˜åˆ°: {save_path}")
    
    if show_plot:
        plt.show()
    else:
        plt.close()


def main():
    parser = argparse.ArgumentParser(description='ç»˜åˆ¶è®­ç»ƒlossæ›²çº¿å¹¶æ£€æµ‹è¿‡æ‹Ÿåˆ')
    parser.add_argument('--history_path', type=str, default=None,
                        help='è®­ç»ƒå†å²JSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--checkpoint_dir', type=str, default='checkpoints',
                        help='checkpoint æ–‡ä»¶ç›®å½•')
    parser.add_argument('--save_path', type=str, default='checkpoints/training_curves.png',
                        help='ä¿å­˜å›¾ç‰‡çš„è·¯å¾„')
    parser.add_argument('--no_show', action='store_true',
                        help='ä¸æ˜¾ç¤ºå›¾ç‰‡ï¼Œåªä¿å­˜')
    
    args = parser.parse_args()
    
    try:
        if args.history_path and os.path.exists(args.history_path):
            history = load_history(args.history_path)
            print(f"æˆåŠŸä» JSON æ–‡ä»¶åŠ è½½è®­ç»ƒå†å²")
        else:
            history = load_history_from_checkpoints(args.checkpoint_dir)
        print(f"æ€»è®­ç»ƒè½®æ•°: {len(history['epoch'])}")
    except (FileNotFoundError, ValueError) as e:
        print(f"é”™è¯¯: {e}")
        return
    
    overfitting_info, error = detect_overfitting(history)
    if not error:
        print("\n" + "="*60)
        print("è¿‡æ‹Ÿåˆæ£€æµ‹ç»“æœ:")
        print("="*60)
        print(overfitting_info['warning'])
        print(f"æœ€ä½³éªŒè¯loss: {overfitting_info['best_val_loss']:.4f} (Epoch {overfitting_info['best_epoch']})")
        print("="*60)
    
    plot_curves(history, save_path=args.save_path, show_plot=not args.no_show)

if __name__ == '__main__':
    main()