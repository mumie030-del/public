import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
import numpy as np
from unet_module import Unet
from tqdm import tqdm
from dataset import Data3Dataset
# ==================== 配置参数 ====================
DATA_DIR = '../data3'
BATCH_SIZE = 1
LEARNING_RATE = 1e-4
NUM_EPOCHS = 100
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
CHECKPOINT_DIR = './checkpoints'
os.makedirs(CHECKPOINT_DIR, exist_ok=True)


#加载数据集
dataset=Data3Dataset(data_root=ROOT_DIR, target_size=(256, 256), num_channels=26)
print(f"总数据集大小: {len(dataset)}")
    
# 2. 划分训练集和验证集 (75% 训练, 25% 验证)
train_size = int(0.75 * len(dataset))
val_size = len(dataset) - train_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
print(f"训练集大小: {len(train_dataset)}, 验证集大小: {len(val_dataset)}")
    
# 3. 创建 DataLoader
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)
    
# 4. 初始化模型
model = Unet(in_channels=26, out_channels=1).to(DEVICE)


print(f"输入通道数: 26, 输出通道数: 1")
    
# 测试一个 batch
sample_img, sample_mask = next(iter(train_loader))
print(f"图像形状: {sample_img[0].shape}, 掩码形状: {sample_mask[0].shape}")
    
# 冻结 Transformer 参数
print("\n冻结 TemporalTransformer 模块参数:")
frozen_count = 0
for name, param in model.named_parameters():
    if 'transformer' in name:
        param.requires_grad = False
        frozen_count += 1
        print(f"  ✓ 冻结: {name}")
print(f"共冻结 {frozen_count} 个参数\n")
    
    # 定义损失函数和优化器（只优化未冻结的参数）
criterion = nn.BCEWithLogitsLoss()
optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LEARNING_RATE)
    
    # 学习率调度器
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)
    
    # 5. 训练循环
best_val_loss = float('inf')
    
for epoch in NUM_EPOCHS:
    model.train()
    train_epoch_loss=[]

    for idx,(images, masks) in enumerate(train_loader, 0):
        images=images.to(torch.float32).to(DEVICE)
        masks=masks.to(torch.float32).to(DEVICE)
        ##前向传播
        output=model(images)
        optimizer.zero_grad()
        loss= criterion(masks,output)
        ##反向传播
        loss.backward()
        optimizer.step()
        train_epoch_loss.append(loss.item())
        train_loss.append(loss.item())
        if idx%(len(train_loader)//2)==0:
            print('epoch={}/{},{}/{} of train,loss={}}'.format(epoch,NUM_EPOCHS,idx,len(train_loader),loss.item()))
    train_epochs_loss.append(np.average(train_epoch_loss))


    model.eval()
    val_epoch_loss=[]
    for idx, (images, masks) in enumerate(valid_loader, 0):
        images=images.to(torch.float32).to(DEVICE)
        masks=masks.to(torch.float32).to(DEVICE)
        output=model(image)
        loss=criterion(masks, output)
        valid_epoch_loss.append(loss.item())
        valid_epoch.append(loss.item())
    valid_epochs_loss.append(np.averge(valid_epoch_loss))

    # 保存最佳模型
    if avg_val_loss < best_val_loss:
        best_val_loss = avg_val_loss
        checkpoint_path = os.path.join(CHECKPOINT_DIR, 'best_model.pth')
        torch.save({
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'train_loss': avg_train_loss,
            'val_loss': avg_val_loss,
            }, checkpoint_path)
        print(f'  ✓ 保存最佳模型到 {checkpoint_path}')
        
        # 每 10 个 epoch 保存一次检查点
    if (epoch + 1) % 10 == 0:
        checkpoint_path = os.path.join(CHECKPOINT_DIR, f'checkpoint_epoch_{epoch+1}.pth')
        torch.save({
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'train_loss': avg_train_loss,
            'val_loss': avg_val_loss,
        }, checkpoint_path)
        print(f'  ✓ 保存检查点到 {checkpoint_path}')
        
    print('-' * 60)
    
print('\n训练完成！')
print(f'最佳验证损失: {best_val_loss:.4f}')
